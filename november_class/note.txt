




CI/CD
ci tools
github actions
gitlab ci/cd
jenkins
circleci
travis ci
Some cd tools
ansible, terraform, helm, agrocd,shell scripting


Declarative (written in statements) and 
Scripted pipeline (written in groovy)

Distributed Builds 
Jenkins - master-agent architecture
Github actions - hosted runners and self-hosted runners

You can use docker as a build agent


Jenkins and Java
sudo apt update
sudo apt install fontconfig openjdk-21-jre
java --version


sudo wget -O /etc/apt/keyrings/jenkins-keyring.asc \
https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key
echo "deb [signed-by=/etc/apt/keyrings/jenkins-keyring.asc]" \
https://pkg.jenkins.io/debian-stable binary/ | sudo tee \
  /etc/apt/sources.list.d/jenkins.list > /dev/null
sudo apt update
sudo apt install jenkins


Common SMTP server ports are
25, 465, 587, and 2525, with 587 being the recommended port for secure email submission, 465 for legacy SMTPS, and 25 for server-to-server communication. Many major email providers use these ports, such as Gmail (smtp.gmail.com on port 587) and Microsoft 365 (smtp.office365.com on port 587). 
 
Common SMTP ports
 
Port 25: The original SMTP port, now mainly used for server-to-server email relay and often blocked to prevent spam.
Port 465: A legacy port for encrypted email using SMTP Secure (SMTPS). It is used when a direct, encrypted connection is needed.
Port 587: The recommended port for secure email submission. It uses STARTTLS to upgrade a plain text connection to an encrypted one.
Port 2525: An alternative port for email submission, often used when other ports are blocked. 
 
Examples from major email providers
 
Gmail: smtp.gmail.com on port 587 (StartTLS) or 465 (SSL).
Microsoft 365: smtp.office365.com on port 587 (StartTLS).
Yahoo Mail: smtp.mail.yahoo.com on port 465 (SSL).
Hotmail/Outlook.com: smtp.live.com on port 587 (StartTLS) or 465 (SSL).
Comcast: smtp.comcast.net on port 587. 
 
GITHUB ACTIONS
In github action , jobs are run on runners
- Built in runners 
- Self - hosted run ers - For complex jobs
Workflows are alwas written in .github/workflow/file-name.yaml 
name - Description of your workflow
Event trigger - what makes the job start (on push, pull etc)
Job- Describe as stage in jenkns 


The syntax consits of lists, dictionaires and values
List is represented with - but nested dictionaries are not
YAML
Yet Another MarkUp Language/ YAML Ain't MarkUp Language

It is human readable unkine json which is machine readable 

Basic Data Types 
Scaler - one name and value
Lists - multiple things, values
Dictiniaries: key-value pairs

Special Characters
# - comment
: - separator
- = lists

use > or | to indicate multiple line command, or comments


HOW TO HOST SELF-RUNNER
github repo > setting> actions> runner> new rnner> choose system specification>
cp the code into your terminal

Tunner - The machine that will exucute your taks, like in jenkins we have the 
slave and master, the slave will execute the jobs specified

CONTIANER VS VIRTUAL MACHINE
Contianer  are lgithweigth, can be resized, can run on no os environment
thay all sgare resources from host 
VM is more secure

Packing an application and its dependencies into a single portable unit
DOCKER
A Docker image is a read-only template containing the instructions and 
components necessary to create a Docker container. It serves as a blueprint 
for deploying and running a containerized application. 
 
  
  
            
Here are the key characteristics of a Docker image:   
  
Read-only:
Once built, a Docker image cannot be modified. Any changes made during the execution
of a container (which is based on an image) are stored in a separate, writable layer 
on top of the image.

Layered structure:
Docker images are composed of multiple layers, where each layer represents a specific 
instruction in the Dockerfile (the script used to build an image). This layering makes 
images efficient, as only changed layers need to be rebuilt when updates occur.

Contains everything needed to run an application:
An image bundles the application code, libraries, dependencies, tools, and 
configurations required for the application to function correctly within a container.

Portable and shareable:
Images can be easily shared and distributed through Docker registries (like Docker Hub), 
allowing consistent deployment across different environments.

Template for containers:
When you run a Docker image, it creates one or more instances of a Docker container, 
each operating as an isolated process in its own environment.


Here are the key characteristics of a Docker image:   
  
Read-only:
Once built, a Docker image cannot be modified. Any changes made during the execution of
 a container (which is based on an image) are stored in a separate, writable layer on top
of the image.

Layered structure:
Docker images are composed of multiple layers, where each layer represents a specific 
instruction in the Dockerfile (the script used to build an image). This layering makes 
images efficient, as only changed layers need to be rebuilt when updates occur.

Contains everything needed to run an application:
An image bundles the application code, libraries, dependencies, tools, and configurations
required for the application to function correctly within a container.

Portable and shareable:
Images can be easily shared and distributed through Docker registries (like Docker Hub), 
allowing consistent deployment across different environments.

Template for containers:
When you run a Docker image, it creates one or more instances of a Docker container, 
each operating as an isolated process in its own environment.

Runtime Instance of an Image:
A Docker container is essentially a running instance of a Docker image. Think of a 
Docker image as a blueprint or a template, and a container as a house built from that 
blueprint.

Isolation and Portability:
Containers provide a loosely isolated environment for your applications. This means the
application within the container is largely independent of the host system's configuration 
and dependencies. This isolation makes them highly portable, allowing you to run the s
ame container consistently across different environments (development, testing, 



production) and operating systems (Linux, Windows).

Lightweight and Efficient:
Unlike traditional virtual machines, which include a full operating system for each 
application, Docker containers share the host operating system's kernel. This makes 
them significantly more lightweight and efficient in terms of resource utilization.

Consistency:
By packaging all dependencies with the application, containers ensure that the application runs consistently regardless of the underlying environment, eliminating "it works on my machine" issues.
Mutable:
While Docker images are read-only, containers are mutable. This means you can make 
changes to a running container, such as installing new packages or modifying configurations,
although these changes are typically not persisted back to the original image unless explicitly committed.

INSTALLING DOECKER 
1. Delete old version of docker or check for existence
for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done

2.
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc
 
# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "${UBUNTU_CODENAME:-$VERSION_CODENAME}") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update


sudo usermod -aG docker $USER
newgrp docker
docker run hello-world


DOCKER COMMANDS
docker pull
docekr start
docker stop
docker ps -a
docker ps
docker run
docekr build
docker volume
docker rm 
docker rmi
docker restart
docker images - template for creeating containers
docker restart
docker logs
docker network
docker inspect
docker tag
docker exec
docker commit
docker attach
docker system prune
docekr login
docekr push


After an image is created using dockerfile or pulled, we need to run the image
to become a container   

Run an image in the bg - use -d flag use -it flag   
run with bash or sh to run commands in the contianer 
use - --name plus name to name the contianer 

-p 81:80 = port mapping from ost to contianer
rm -f to remove a runnign container 
docker prune -af - remove all running and stopped containers
docker attach - runns the command and hangs your sdtn

Use docker exec -it continaer_nmae bash to open the home of the container


HOW TO MINIMISE YOUR DOCKER CONTIANER 
- Use a small base image 
- INstall dependencies in side the image rather than use latest which takes 
up space

.dockerignore
Dockerfile
Syntax is always  uppercase
FROM - Base image
Recmended- distroless, slim, alpine 
dictoless- very secure because no os is needed

RUN- Install anything needed to run the application
avoid using multiple run commands
don't add unnecessary files to your dockerfile

WORKDIR - Where you want your project to run from

COPY - copy sth from host to the contianer
cp - Copy form the container to another path 
ADD- Fetch dependncies from outside the hosts. This is normally url fom github etc

CMD - Default value your caoniaer needs to run but it is only one
Entry poitn - Cna be many 

multistage doeker files prvents using huge sixe of dockerfile


In a production env we use npm run built to create a production ready server

IN development, we use the package.json to specify the dependencies but in 
production it's different

dicst folder is meant for production grade application
This is where frameworks becomes useful 
Normally t is the dist / .build prioduction reasy foolder that is copied
and deployed unto the server

Artefact- the result that comes after building


Contianers runs on bridged network adapter , they can communicate with each
other but not the hosts 
To solve tehis :
1. Host the db on a server that has a public IP
2. Host the dd in teh cloud 
3. 

Docker Networking
How contianers communicate with each other 
Docker creates 3 networks
1. Bridged 
2. hosts
3.Null/none
others: overlay , mac vlan


How to create a docker network
docker network --driver (bridge,host,null) desired_name
docker network --driver bridge wtf-network


Attach A Network TO A contianer That You created
docker network connect
docker run -t --name .... --network network_name

HOW TO ATTACH A NETWORK TO A RUNNING CONTIANER 



DOCKER volume
docker volume create wtf_volume
wtf_volume
afuaantwiwaa@DESKTOP-IMQ4NGF:~$ docker volume ls
DRIVER    VOLUME NAME
local     wtf_volume

Types
- Anonymous volume: NO name attached to the volume
- Named volume

 docker run -d --name anonymous_contianer -p 5002:5173 -v /volume:/app  wtf_backend:v1
5a92c0008557587e9b90dc1deca164e032b38b1b43edec3e6b612935915387b6 
This is how to do a point mount
stop contianers using the volume beofre deleting the volume

To attach a volume to a contianer: docker run -d -v <volume_name>:<path_in_container> <image_name>
eg:
Attach an existing volume named mydata to /app/data inside the container:
docker run -d --name mycontainer -v mydata:/app/data myimage

docker run -d --name wtf_nginx -p 85:80 -v .:/usr/share/nginx/html nginx



It is the slash that differs a vulume and a bind mount. A bind mount has a 
slash. Exmples::
docker run -d --name NAME -p HOST_PORT:CONTAINER_PORT -v /app IMAGE_NAME OR ID => anonymous
 
docker run -d --name NAME -p HOST_PORT:CONTAINER_PORT -v VOLUME_NAME:/app IMAGE_NAME OR ID  => named volume
 
docker run -d --name NAME -p HOST_PORT:CONTAINER_PORT -v /volume:/app IMAGE_NAME OR ID => bind mount


"""
Bind mount:
• You control the host path.
• You point to an exact directory on your system.
• Good for development, editing code live.
• Breaks if host path changes.
• Example:
docker run -v /home/user/app:/usr/src/app node
volume:
• Docker controls the storage location.
• You reference it by a name, not a path.
• Good for production and long term data.
• Easier to move, backup, and manage.
• Example:
docker volume create appdata
docker run -v appdata:/var/lib/mysql mysql
"""

HOW TO PUSH THE CONTIANER/IMAGE TO DOCKER 
1. Docker image but be the smae as the one on docker hub
2. provide credentials


TO PUSH A DOCKER IMAGE TO DOCKER Hub
- Tag the docker image , you can use the same name
:docker tag mongo:6 antwiwaa/mongo:6
-PUsh Image: docker push antwiwaa/mongo:6

DOker compose
It is used to run multiple application of a 3 tier application
It is a sinlge node architecture but also provide container orchestration by 
runnung the 3 tier application with one command
Horizontal scaling: by using docker compose up --scale 

use: docker-compose up -d --build 

HOW TO USE DOCKER AS A BUILD agent/ Build tools
Jenkins pulls the image from docker and after uses it as a node and deletes it after
It is used to safe cost and for distributed builds 

pipeline {
    agent {
      docker {
        image "node:22.21.0-slim"
        args '-u root:root'
         }
      }
 
 
    stages {
 
        stage('Checkout') {
            steps {
                git branch: 'peter-branch',
                    url: 'https://github.com/bigcephas1/React-ToDoList.git'
            }
        }
 
        stage('Frontend Build') {
            steps {
                dir('dive-react-app') {
                    echo "Installing frontend dependencies"
                    sh 'npm install'
 
                    echo "Running lint"
                    sh 'npm run lint'
 
                    echo "Building frontend"
                    sh 'npm run build'
                }
            }
        }
 
        stage('Backend Install') {
            steps {
                dir('backend') {
                    echo "Installing backend dependencies"
                    sh 'npm install'
 
                    echo "Running backend tests (instead of starting server)"
                    sh 'npm test || true'   // prevents failure if no tests exist
                }
            }
        }
 
    }
 
    post {
        always {
            cleanWs()
        }
        success {
            emailext(
                subject: "SUCCESS: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'",
                body: "The build ${env.BUILD_URL} completed successfully.",
                to: "ukpabipeteru@gmail.com"
            )
        }
        failure {
            emailext(
                subject: "FAILED: Job '${env.JOB_NAME} [${env.BUILD_NUMBER}]'",
                body: "The build ${env.BUILD_URL} failed. Please check the logs.",
                to: "ukpabipeteru@gmail.com"
            )
        }
    }
}